{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "confident-project",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (from category_encoders) (0.23.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (from category_encoders) (1.6.1)\n",
      "Requirement already satisfied: pandas>=0.21.1 in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (from category_encoders) (1.2.2)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (from category_encoders) (0.12.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (from category_encoders) (1.19.5)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (from category_encoders) (0.5.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (from pandas>=0.21.1->category_encoders) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
      "Requirement already satisfied: six in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "raising-friendly",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "orange-pillow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tpot in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (0.11.7)\n",
      "Requirement already satisfied: stopit>=1.1.1 in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (from tpot) (1.1.2)\n",
      "Requirement already satisfied: deap>=1.2 in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (from tpot) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.16.3 in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (from tpot) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (from tpot) (0.23.2)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (from tpot) (1.2.2)\n",
      "Requirement already satisfied: update-checker>=0.16 in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (from tpot) (0.18.0)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (from tpot) (4.56.0)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (from tpot) (1.0.1)\n",
      "Requirement already satisfied: scipy>=1.3.1 in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (from tpot) (1.6.1)\n",
      "Requirement already satisfied: xgboost>=1.1.0 in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (from tpot) (1.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->tpot) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->tpot) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=0.24.2->tpot) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22.0->tpot) (2.1.0)\n",
      "Requirement already satisfied: requests>=2.3.0 in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (from update-checker>=0.16->tpot) (2.25.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (1.26.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (4.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "allied-cancer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (from torch) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\innovate1\\anaconda3\\lib\\site-packages (from torch) (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "boring-drilling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías\n",
    "import numpy as np # algebra lineal\n",
    "import pandas as pd # manipulacion de datos\n",
    "from scipy.stats import variation # coeficiente de variación\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Input\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "turkish-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import *\n",
    "import category_encoders as ce\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sustained-prize",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\innovate1\\Anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "#Train\n",
    "Fecha_inicial_train = pd.Timestamp(2016,1,1)\n",
    "Fecha_final_train   = pd.Timestamp(2021,1,10)\n",
    "\n",
    "#Test\n",
    "Fecha_inicial_test  = pd.Timestamp(2019,1,1)\n",
    "Fecha_final_test    = pd.Timestamp(2020,8,1)\n",
    "\n",
    "#Prueba\n",
    "Fecha_inicial_prueba  = pd.Timestamp(2021,1,1) \n",
    "Fecha_final_prueba  = pd.Timestamp(2021,12,31)\n",
    "\n",
    "list_claves = [\n",
    "                'ARTICULO' , 'DISENO' , 'COMBINACION', 'Fc.Corte' , 'TITULO_U','NUM_CABOS_U','Telar','LIGAMENTO_FONDO','LIGAMENTO_ORILLO',\n",
    "                   'DIENTES/CM_PEINE','HILOS/DIENTE_FONDO','HILOS/DIENTE_ORILLO','ANCHO_PEINE','ANCHO_CRUDO','%E_URDIMBRE',\n",
    "                  'TOTAL_HILOS/ANCHO_CRUDO','PASADAS/CM_T1','PORC_PASADAS/CM_T1' ,'GR/MTL_U','GR/MTL_T1','TOTAL_PASADAS','PORC_GR/MTL_U','PORC_GR/MTL_T1','TOTAL_GR/MTL', 'MAQUINA_PINZAS',\n",
    "                   'NUM_COLORES_U','NUM_COLORES_T','AGUA    ','LUMINOSIDAD_T_1', 'LUMINOSIDAD_U_1', 'LUMINOSIDAD_T_2', 'LUMINOSIDAD_U_2', 'LUMINOSIDAD_T_3',\n",
    "                   'LUMINOSIDAD_U_3', 'LUMINOSIDAD_T_4', 'LUMINOSIDAD_U_4', 'LUMINOSIDAD_T_5', 'LUMINOSIDAD_U_5','LUMINOSIDAD_T_6', 'LUMINOSIDAD_U_6', \n",
    "                   'FACT_COB_U', 'FACT_COB_T','FACT_COB_TOTAL_REAL', 'TUPIDEZ','Ne_prom','CV% Ne_prom','cN/tex_prom','TPI_prom','FT_prom','CV% TPI_prom',\n",
    "                   'E%_prom','CV% E_prom','CV%R_prom','CVm%_prom','I_prom','PD(-40%)_prom','PD(-50%)_prom','PG(+35%)_prom','PG(+50%)_prom','NEPS(+140%)_prom','NEPS(+200%)_prom',\n",
    "                   'H_prom','Sh_prom','var_Ne_prom','var_cN/tex_prom','var_TPI_prom','var_E%_prom','%falla_R_prom','%falla_E_prom' , 'CMPX DE PARO POR URDIMBRE'\n",
    "              ]\n",
    "\n",
    "list_predictors = [\n",
    "                  'TITULO_U','NUM_CABOS_U','Telar','LIGAMENTO_FONDO','LIGAMENTO_ORILLO',\n",
    "                   'DIENTES/CM_PEINE','HILOS/DIENTE_FONDO','HILOS/DIENTE_ORILLO','ANCHO_PEINE','ANCHO_CRUDO','%E_URDIMBRE',\n",
    "                  'TOTAL_HILOS/ANCHO_CRUDO','PASADAS/CM_T1','PORC_PASADAS/CM_T1' , 'RPM',\n",
    "                   'GR/MTL_U','GR/MTL_T1','TOTAL_PASADAS','PORC_GR/MTL_U','PORC_GR/MTL_T1','TOTAL_GR/MTL', 'MAQUINA_PINZAS',\n",
    "                   'NUM_COLORES_U','NUM_COLORES_T','AGUA    ','LUMINOSIDAD_T_1', 'LUMINOSIDAD_U_1', 'LUMINOSIDAD_T_2', 'LUMINOSIDAD_U_2', 'LUMINOSIDAD_T_3',\n",
    "                   'LUMINOSIDAD_U_3', 'LUMINOSIDAD_T_4', 'LUMINOSIDAD_U_4', 'LUMINOSIDAD_T_5', 'LUMINOSIDAD_U_5','LUMINOSIDAD_T_6', 'LUMINOSIDAD_U_6', \n",
    "                   'FACT_COB_U', 'FACT_COB_T','FACT_COB_TOTAL_REAL', 'TUPIDEZ','Ne_prom','CV% Ne_prom','cN/tex_prom','TPI_prom','FT_prom','CV% TPI_prom',\n",
    "                   'E%_prom','CV% E_prom','CV%R_prom','CVm%_prom','I_prom','PD(-40%)_prom','PD(-50%)_prom','PG(+35%)_prom','PG(+50%)_prom','NEPS(+140%)_prom','NEPS(+200%)_prom',\n",
    "                   'H_prom','Sh_prom','var_Ne_prom','var_cN/tex_prom','var_TPI_prom','var_E%_prom','%falla_R_prom','%falla_E_prom'\n",
    "                  ]\n",
    "\n",
    "list_targets = ['CMPX DE PARO POR URDIMBRE']\n",
    "#Se leen los datos necesarios para el proyecto\n",
    "Data_Muestras = pd.read_csv(\"Muestras.csv\")\n",
    "Data_Total = pd.read_excel('Data_total_analisis.xls')\n",
    "temp_Data = Data_Total[list(['Fc.Corte']) +  list_predictors + list_targets ]\n",
    "DataFrame_filtrado = temp_Data.copy()\n",
    "#Se definen los limites de los datos de entrenamiento\n",
    "DataFrame_filtrado = DataFrame_filtrado.loc[ (0 < DataFrame_filtrado['CMPX DE PARO POR URDIMBRE'])\n",
    "                                                         & (DataFrame_filtrado['CMPX DE PARO POR URDIMBRE']<7.5)\n",
    "                                                        ]\n",
    "DataFrame_filtrado.shape\n",
    "DataFrame_filtrado.reset_index(drop=True,inplace=True)\n",
    "DataFrame_filtrado_total = DataFrame_filtrado.copy()\n",
    "#Se definen los limites de los datos de muestras\n",
    "Data_Muestras = Data_Muestras.loc[ (0 < Data_Muestras['CMPX DE PARO POR URDIMBRE'])\n",
    "                                                         & (Data_Muestras['CMPX DE PARO POR URDIMBRE']<7.5)\n",
    "                                                        ]\n",
    "Data_Muestras.shape\n",
    "Data_Muestras.reset_index(drop=True,inplace=True)\n",
    "#Se limpian los predictos \n",
    "predictores_numericos = [i for i in list_predictors if  'float' in str(DataFrame_filtrado[i].dtype) or 'int' in str(DataFrame_filtrado[i].dtype)]\n",
    "predictores_categoricos = [i for i in list_predictors if i not in predictores_numericos]\n",
    "df=DataFrame_filtrado.copy()\n",
    "#quitar variables correlacionadas\n",
    "df=DataFrame_filtrado.copy()\n",
    "# Create correlation matrix\n",
    "corr_matrix = df[predictores_categoricos+predictores_numericos].corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "for i in to_drop:\n",
    " if i in predictores_numericos:\n",
    "   predictores_numericos.remove(i)\n",
    " elif i in predictores_categoricos:\n",
    "   predictores_categoricos.remove(i)\n",
    "   \n",
    "import datetime\n",
    "#Se hara un entremiento entre 2016 a 2018\n",
    "#La validacion sera de 2018 a 2019\n",
    "X_train= df[ (Fecha_inicial_train <= df['Fc.Corte'] )\n",
    "            & (df['Fc.Corte']  < Fecha_final_train ) ]\n",
    "X_test= df[\n",
    "           (Fecha_inicial_test <= df['Fc.Corte'] ) &\n",
    "           (df['Fc.Corte']  < Fecha_final_test)\n",
    "           ]\n",
    "y_train = df[list_targets[0]][X_train.index]\n",
    "y_test = df[list_targets[0]][X_test.index]\n",
    "#Los datos de prueba final seran del año 2020\n",
    "X_prueba_campo = df[\n",
    "                    (Fecha_inicial_prueba <= df['Fc.Corte'] ) &\n",
    "                    (df['Fc.Corte']  < Fecha_final_prueba)\n",
    "                    ]\n",
    "y_prueba_campo = df[list_targets[0]][X_prueba_campo.index]\n",
    "X=df[list_predictors]\n",
    "X_muestras = Data_Muestras[list_predictors]\n",
    "y_muestras = Data_Muestras[list_targets[0]]\n",
    "#Separamos las variables categoricas\n",
    "train = X_train[predictores_categoricos]\n",
    "test = X_test[predictores_categoricos]\n",
    "#Se les aplica el encoder\n",
    "encoder_mean = ce.TargetEncoder(cols = predictores_categoricos ,handle_unknown= 'ignore' )\n",
    "OH_cols_train = encoder_mean.fit_transform(train[predictores_categoricos],y_train)\n",
    "OH_cols_test = encoder_mean.transform(test[predictores_categoricos],y_test)\n",
    "# Eliminamos las columnas categoricas de nuestra data para luego remplazarlas con las resultantes del HOE\n",
    "num_X_train = X_train[predictores_numericos]\n",
    "num_X_test = X_test[predictores_numericos]\n",
    "# Concatenable\n",
    "X_train_escalable = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "X_test_escalable = pd.concat([num_X_test, OH_cols_test], axis=1)\n",
    "# se escalan los datos numéricos\n",
    "scaler = StandardScaler()\n",
    "Num_X_Scaler_train=pd.DataFrame(scaler.fit_transform(X_train_escalable))\n",
    "Num_X_Scaler_test=pd.DataFrame(scaler.transform(X_test_escalable))\n",
    "#Elimina los indices asi que los volvemos a poner\n",
    "Num_X_Scaler_train.index = X_train.index\n",
    "Num_X_Scaler_test.index = X_test.index\n",
    "# Adecuamos la nomeclatura \n",
    "OH_X_train = Num_X_Scaler_train\n",
    "OH_X_test = Num_X_Scaler_test\n",
    "#Asignamos los nombres\n",
    "lista_nombres_numericos = X_train_escalable.columns \n",
    "lista_nombres = list(lista_nombres_numericos)\n",
    "OH_X_train.columns = lista_nombres\n",
    "OH_X_test.columns = lista_nombres\n",
    "#Separamos las variables categoricas\n",
    "prueba_campo = X_prueba_campo[predictores_categoricos]\n",
    "#Se les aplica el encoder\n",
    "OH_cols_prueba_campo = encoder_mean.transform(prueba_campo[predictores_categoricos],y_prueba_campo)\n",
    "# Eliminamos las columnas categoricas de nuestra data para luego remplazarlas con las resultantes del HOE\n",
    "num_X_prueba_campo = X_prueba_campo[predictores_numericos]\n",
    "# Concatenable\n",
    "X_prueba_campo_escalable = pd.concat([num_X_prueba_campo, OH_cols_prueba_campo], axis=1)\n",
    "# se escalan los datos numéricos\n",
    "Num_X_Scaler_prueba_campo=pd.DataFrame(scaler.transform(X_prueba_campo_escalable))\n",
    "#Elimina los indices asi que los volvemos a poner\n",
    "Num_X_Scaler_prueba_campo.index = X_prueba_campo.index\n",
    "# Adecuamos la nomeclatura \n",
    "OH_X_prueba_campo = Num_X_Scaler_prueba_campo\n",
    "#Asignamos los nombres\n",
    "lista_nombres_numericos = X_prueba_campo_escalable.columns \n",
    "lista_nombres = list(lista_nombres_numericos)\n",
    "OH_X_prueba_campo.columns = lista_nombres\n",
    "#USAREMOS LAS PREDICCIONES DEL TOTAL COMO OTRA COLUMNA PARA LA NN\n",
    "X_cols = pd.DataFrame(encoder_mean.transform(X.iloc[pd.concat([X_train,X_test]).index][predictores_categoricos].astype(str)))\n",
    "X_cols.index = pd.concat([X_train,X_test]).index\n",
    "num_X = X.iloc[pd.concat([X_train,X_test]).index][predictores_numericos]\n",
    "X_escalable = pd.concat([num_X, X_cols], axis=1)\n",
    "X_total=pd.DataFrame(scaler.transform(X_escalable))\n",
    "X_total.index = X_escalable.index\n",
    "#Renombramos a las columnas\n",
    "lista_nombres_numericos = X_escalable.columns \n",
    "lista_nombres = list(lista_nombres_numericos)\n",
    "X_total.columns = lista_nombres\n",
    "#Separamos las variables categoricas\n",
    "muestras_pruebas = X_muestras[predictores_categoricos]\n",
    "#Se les aplica el encoder\n",
    "OH_cols_X_muestras_pruebas = encoder_mean.transform(muestras_pruebas[predictores_categoricos],y_muestras)\n",
    "# Eliminamos las columnas categoricas de nuestra data para luego remplazarlas con las resultantes del HOE\n",
    "num_X_muestras_pruebas= X_muestras[predictores_numericos]\n",
    "# Concatenable\n",
    "X_muestras_pruebas_escalable = pd.concat([num_X_muestras_pruebas, OH_cols_X_muestras_pruebas], axis=1)\n",
    "# se escalan los datos numéricos\n",
    "Num_X_Scaler_prueba_campo=pd.DataFrame(scaler.transform(X_muestras_pruebas_escalable))\n",
    "#Elimina los indices asi que los volvemos a poner\n",
    "Num_X_Scaler_prueba_campo.index = X_muestras.index\n",
    "# Adecuamos la nomeclatura \n",
    "OH_X_muestras = Num_X_Scaler_prueba_campo\n",
    "#Asignamos los nombres\n",
    "lista_nombres_numericos = X_muestras_pruebas_escalable.columns \n",
    "lista_nombres = list(lista_nombres_numericos)\n",
    "OH_X_muestras.columns = lista_nombres\n",
    "#Evitamos encontrar valores 0\n",
    "(OH_X_prueba_campo).fillna(0 , inplace= True)\n",
    "(OH_X_test).fillna(0 , inplace= True)\n",
    "(X_total).fillna(0 , inplace= True)\n",
    "(OH_X_muestras).fillna(0 , inplace= True)\n",
    "#Se planteo el uso de log sobre la variable a predecir para minimizar el error de prediccion con \n",
    "#Numeros elevados\n",
    "y_train = np.log(y_train)\n",
    "y_test = np.log(y_test)\n",
    "y_prueba_campo = np.log(y_prueba_campo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "common-thumb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpot: 0.11.7\n"
     ]
    }
   ],
   "source": [
    "# check tpot version\n",
    "import tpot\n",
    "print('tpot: %s' % tpot.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "spare-italic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd49af01ca4544f5b43201eb5d2dca24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -0.4301611194241695\n",
      "\n",
      "Generation 2 - Current best internal CV score: -0.4290605917814264\n",
      "\n",
      "Generation 3 - Current best internal CV score: -0.4290605917814264\n",
      "\n",
      "Generation 4 - Current best internal CV score: -0.4290605917814264\n",
      "\n",
      "Generation 5 - Current best internal CV score: -0.4290207215344088\n",
      "\n",
      "Generation 6 - Current best internal CV score: -0.4290207215344088\n",
      "\n",
      "Generation 7 - Current best internal CV score: -0.42605454843470464\n",
      "\n",
      "Generation 8 - Current best internal CV score: -0.42605454843470464\n",
      "\n",
      "Generation 9 - Current best internal CV score: -0.42605454843470464\n",
      "\n",
      "Generation 10 - Current best internal CV score: -0.42605454843470464\n",
      "\n",
      "Generation 11 - Current best internal CV score: -0.42605454843470464\n",
      "\n",
      "Generation 12 - Current best internal CV score: -0.4259887466846733\n",
      "\n",
      "Generation 13 - Current best internal CV score: -0.4259887466846733\n",
      "\n",
      "Generation 14 - Current best internal CV score: -0.4255302497730075\n",
      "\n",
      "Generation 15 - Current best internal CV score: -0.4255302497730075\n",
      "\n",
      "Generation 16 - Current best internal CV score: -0.4255302497730075\n",
      "\n",
      "Generation 17 - Current best internal CV score: -0.4248852747327394\n",
      "\n",
      "Generation 18 - Current best internal CV score: -0.4218311124583587\n",
      "\n",
      "Generation 19 - Current best internal CV score: -0.4218311124583587\n",
      "\n",
      "Generation 20 - Current best internal CV score: -0.421463160265836\n",
      "\n",
      "Generation 21 - Current best internal CV score: -0.421463160265836\n",
      "\n",
      "Generation 22 - Current best internal CV score: -0.421463160265836\n",
      "\n",
      "Generation 23 - Current best internal CV score: -0.421463160265836\n",
      "\n",
      "Generation 24 - Current best internal CV score: -0.421463160265836\n",
      "\n",
      "Generation 25 - Current best internal CV score: -0.421463160265836\n",
      "\n",
      "Generation 26 - Current best internal CV score: -0.421463160265836\n",
      "\n",
      "Generation 27 - Current best internal CV score: -0.421463160265836\n",
      "\n",
      "Generation 28 - Current best internal CV score: -0.421463160265836\n",
      "\n",
      "Generation 29 - Current best internal CV score: -0.421463160265836\n",
      "\n",
      "Generation 30 - Current best internal CV score: -0.42124290312052776\n",
      "\n",
      "Generation 31 - Current best internal CV score: -0.42124290312052776\n",
      "\n",
      "Generation 32 - Current best internal CV score: -0.42124290312052776\n",
      "\n",
      "Generation 33 - Current best internal CV score: -0.42124290312052776\n",
      "\n",
      "Generation 34 - Current best internal CV score: -0.42124290312052776\n",
      "\n",
      "Generation 35 - Current best internal CV score: -0.421136314559271\n",
      "\n",
      "Generation 36 - Current best internal CV score: -0.421136314559271\n",
      "\n",
      "Generation 37 - Current best internal CV score: -0.421136314559271\n",
      "\n",
      "Generation 38 - Current best internal CV score: -0.421136314559271\n",
      "\n",
      "Generation 39 - Current best internal CV score: -0.4206791879308313\n",
      "\n",
      "Generation 40 - Current best internal CV score: -0.41915741107012155\n",
      "\n",
      "Generation 41 - Current best internal CV score: -0.41915741107012155\n",
      "\n",
      "Generation 42 - Current best internal CV score: -0.41915741107012155\n",
      "\n",
      "Generation 43 - Current best internal CV score: -0.41915741107012155\n",
      "\n",
      "Generation 44 - Current best internal CV score: -0.41915741107012155\n",
      "\n",
      "Generation 45 - Current best internal CV score: -0.41915741107012155\n",
      "\n",
      "Generation 46 - Current best internal CV score: -0.4190073758721281\n",
      "\n",
      "Generation 47 - Current best internal CV score: -0.4190073758721281\n",
      "\n",
      "Generation 48 - Current best internal CV score: -0.4190073758721281\n",
      "\n",
      "Generation 49 - Current best internal CV score: -0.4189714916403225\n",
      "\n",
      "Generation 50 - Current best internal CV score: -0.4189714916403225\n",
      "\n",
      "Generation 51 - Current best internal CV score: -0.4189714916403225\n",
      "\n",
      "Generation 52 - Current best internal CV score: -0.4189714916403225\n",
      "\n",
      "Generation 53 - Current best internal CV score: -0.4189714916403225\n",
      "\n",
      "Generation 54 - Current best internal CV score: -0.4189714916403225\n",
      "\n",
      "Generation 55 - Current best internal CV score: -0.4189714916403225\n",
      "\n",
      "Generation 56 - Current best internal CV score: -0.4189714916403225\n",
      "\n",
      "Generation 57 - Current best internal CV score: -0.4189714916403225\n",
      "\n",
      "Generation 58 - Current best internal CV score: -0.4189714916403225\n",
      "\n",
      "Generation 59 - Current best internal CV score: -0.4189714916403225\n",
      "\n",
      "Generation 60 - Current best internal CV score: -0.4189714916403225\n",
      "\n",
      "Generation 61 - Current best internal CV score: -0.4189714916403225\n",
      "\n",
      "Generation 62 - Current best internal CV score: -0.4185815213713166\n",
      "\n",
      "Generation 63 - Current best internal CV score: -0.4185815213713166\n",
      "\n",
      "Generation 64 - Current best internal CV score: -0.4185815213713166\n",
      "\n",
      "Generation 65 - Current best internal CV score: -0.4185815213713166\n",
      "\n",
      "Generation 66 - Current best internal CV score: -0.4185815213713166\n",
      "\n",
      "Generation 67 - Current best internal CV score: -0.4185815213713166\n",
      "\n",
      "Generation 68 - Current best internal CV score: -0.4185815213713166\n",
      "\n",
      "Generation 69 - Current best internal CV score: -0.4185815213713166\n",
      "\n",
      "Generation 70 - Current best internal CV score: -0.4185815213713166\n",
      "\n",
      "Generation 71 - Current best internal CV score: -0.4185815213713166\n",
      "\n",
      "Generation 72 - Current best internal CV score: -0.4185815213713166\n",
      "\n",
      "Generation 73 - Current best internal CV score: -0.4185815213713166\n",
      "\n",
      "Generation 74 - Current best internal CV score: -0.4185815213713166\n",
      "\n",
      "Generation 75 - Current best internal CV score: -0.4185815213713166\n",
      "\n",
      "Generation 76 - Current best internal CV score: -0.4185815213713166\n",
      "\n",
      "Generation 77 - Current best internal CV score: -0.4185815213713166\n",
      "\n",
      "Generation 78 - Current best internal CV score: -0.4185815213713166\n",
      "\n",
      "Generation 79 - Current best internal CV score: -0.4185815213713166\n",
      "\n",
      "Generation 80 - Current best internal CV score: -0.4185815213713166\n",
      "\n",
      "Generation 81 - Current best internal CV score: -0.4185815213713166\n",
      "\n",
      "Generation 82 - Current best internal CV score: -0.4185815213713166\n",
      "\n",
      "1060.16 minutes have elapsed. TPOT will close down.\n",
      "TPOT closed during evaluation in one generation.\n",
      "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
      "\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "\n",
      "Best pipeline: ExtraTreesRegressor(GradientBoostingRegressor(MaxAbsScaler(StandardScaler(input_matrix)), alpha=0.8, learning_rate=0.01, loss=huber, max_depth=3, max_features=0.6500000000000001, min_samples_leaf=11, min_samples_split=17, n_estimators=100, subsample=0.7000000000000001), bootstrap=False, max_features=0.6000000000000001, min_samples_leaf=15, min_samples_split=18, n_estimators=100)\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTRegressor\n",
    "# Definimos el modelo\n",
    "model = TPOTRegressor(max_time_mins = 1060 ,\n",
    "                      generations = None, \n",
    "                      population_size=100,\n",
    "                      scoring='neg_mean_squared_error',\n",
    "                      verbosity=2, \n",
    "                      random_state=51,\n",
    "                      n_jobs=1 )\n",
    "\n",
    "# Se entrena\n",
    "model.fit(OH_X_train, y_train)\n",
    "\n",
    "# exportamos\n",
    "model.export('tpot_insurance_best_model_fds.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-mouth",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
